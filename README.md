Note: This is a small learning and reference project created to explore architectural boundaries when embedding AI into backend orchestration. The code intentionally prioritizes clarity of flow over production-grade structure or optimizations.

AI-Assisted Case Orchestrator

This project is a small reference implementation that demonstrates how an AI model can be integrated into an enterprise-style backend flow as a recommendation component, while keeping execution deterministic, auditable and safe.

The service exposes a simple case-processing API where an AI model is used only to recommend the next step and routing based on contextual information and execution history.
All execution decisions are enforced by deterministic guardrails.

⸻

What problem this project addresses

Many AI agent architectures allow the model to directly control tools and execution flow.

This project intentionally explores a safer design:
	•	the AI recommends
	•	the orchestration layer validates
	•	the orchestration layer executes

The goal is to show how AI can be embedded into an integration or workflow pipeline without breaking operational guarantees such as idempotency, replayability and auditability.

⸻

High level flow

	HTTP request
	   ↓
	process_case()      [main.py]
	   ↓
	build idempotency key
	   ↓
	load case from DB
	   ↓
	get_or_create_decision()   [orchestration.py]
	   ↓
	    ├── reuse decision from DB
	    └── OR call AI → store decision
	   ↓
	guardrails()
	   ↓
	execute backend OR manual
	   ↓
	write audit log
	   ↓
	HTTP response

⸻

Design principles

This project follows three strict architectural rules:
	1.	The AI model never executes backend actions.
	2.	The AI output must follow a strict JSON contract.
	3.	The final execution path is always decided by deterministic logic.

⸻
## Detailed architecture diagram

![Detailed architecture diagram](/architecture-detailed.png)

What does “AI decision” mean in this project

In this project, an AI decision does not mean automatic execution.

It is only a structured recommendation generated by the AI based on the incoming task description and the current case context.

The AI converts unstructured or semi-structured information (for example free-text instructions or error descriptions) into a small structured object such as:

intent
next step
route target
retry strategy
risk score
confidence
reason code

This object is referred to as the AI decision in this project.

It represents only an interpretation of the situation and a recommendation for the next step.

⸻

Why is AI used here

AI is used only to solve an interpretation problem.

In real systems, task descriptions, operator notes and error messages are often unstructured and inconsistent.

For example:

Partner API failed again with timeout, please retry for policy 4711

From such text, the system must infer:
	•	what the user intends
	•	what type of action is being requested
	•	which backend capability is required

Implementing this using only rules and string matching becomes brittle and difficult to maintain.

The AI model is therefore used to translate unstructured input into structured information.

⸻

What the AI does not do

The AI is not allowed to:
	•	execute backend calls
	•	update business data
	•	change process state
	•	decide permissions
	•	control the workflow

All execution decisions are made by deterministic code using explicit guardrails.

⸻

Execution remains deterministic

After an AI recommendation is produced, the orchestration layer applies strict validation and rule checks such as:
	•	confidence
	•	risk score
	•	case state
	•	retry limits
	•	allowed intents

Only if all guardrails pass will a backend operation be executed.

This design intentionally separates:

interpretation (AI)
control and execution (deterministic orchestration logic)

This keeps the system predictable, auditable and safe.

⸻

Reliability and fallback

External AI calls are treated as unreliable dependencies.

If the AI call fails due to quota limits, rate limiting, network issues or invalid responses, the service produces a conservative fallback decision and routes the case to manual review.

The fallback decision is persisted using the same idempotency mechanism so that retries remain deterministic.

⸻

Technology stack

Python
FastAPI
SQLite
OpenAI API (optional – graceful fallback is implemented)

⸻

Setup

Create a virtual environment

	python3 -m venv .venv
	source .venv/bin/activate

Install dependencies

	pip install -r requirements.txt

Create the database

	sqlite3 app.db < init_db.sql

Insert one sample case

	sqlite3 app.db “INSERT INTO cases VALUES (‘C1001’,‘OPEN’,1,‘TIMEOUT’,‘MEDIUM’);”

⸻

Configuration

Set the OpenAI API key (optional)

	export OPENAI_API_KEY=“your_api_key”

⸻

Run the service

	uvicorn app.main:app –reload
	
	API documentation
	
	http://127.0.0.1:8000/docs

⸻

Example request

	POST /case-task
	
	case_id: C1001
	description: Partner API failed again with timeout, please retry for policy 4711
	channel: SYSTEM
	user_role: OPS

⸻

What to observe
	•	The AI decision is persisted using an idempotency key
	•	Retrying the same request does not invoke the model again
	•	Guardrails decide whether execution is allowed
	•	When the AI call is unavailable, the flow degrades safely to manual review
	•	Every execution attempt is written to an audit log

⸻

Scope and limitations

This project is intentionally small and focuses only on architectural boundaries between:

probabilistic reasoning (AI recommendations)
deterministic orchestration and execution
It is not intended to be a production-ready framework, but a reference implementation for experimenting with AI-assisted orchestration patterns.k, but a reference implementation for experimenting with AI-assisted orchestration patterns.
